The [AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago) ([paper](https://www.nature.com/articles/nature16961)), [AlphZero](https://www.deepmind.com/blog/alphazero-shedding-new-light-on-chess-shogi-and-go) ([paper](https://arxiv.org/abs/1712.01815)), and [Muzero](https://www.deepmind.com/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules) ([paper](https://arxiv.org/abs/1911.08265)) algorithms created by [Deepmind](https://www.deepmind.com/) were made to solve complex tasks comparable to those met in the real world. It so happens that games are an accurate representation of some of those tasks, and so, games are a great way to test the learning capabilities as well as the generality of these models. The Muzero algorithm is the compilement of its predecessors (AlphaGo and AlphaZero) which are inferior to it in both accuracy and robusticity. The [template](https://arxiv.org/src/1911.08265v2/anc/pseudocode.py) was used here to reproduce the Muzero algorithm usng the [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) module, which I recommend be swapped according to one's needs ([TPU](https://sites.research.google/trc/about/)).  
